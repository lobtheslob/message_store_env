 INFO [2019-08-14 16:23:28,288] ({main} RemoteInterpreterServer.java[main]:261) - URL:jar:file:/zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar!/org/apache/zeppelin/interpreter/remote/RemoteInterpreterServer.class
 INFO [2019-08-14 16:23:28,356] ({main} RemoteInterpreterServer.java[<init>]:162) - Launching ThriftServer at 172.17.0.3:42113
 INFO [2019-08-14 16:23:28,366] ({main} RemoteInterpreterServer.java[<init>]:166) - Starting remote interpreter server on port 42113
 INFO [2019-08-14 16:23:28,367] ({Thread-0} RemoteInterpreterServer.java[run]:203) - Starting remote interpreter server on port 42113
 INFO [2019-08-14 16:23:29,412] ({Thread-1} RemoteInterpreterUtils.java[registerInterpreter]:165) - callbackHost: 172.17.0.3, callbackPort: 33817, callbackInfo: CallbackInfo(host:172.17.0.3, port:42113)
 INFO [2019-08-14 16:23:29,669] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2019-08-14 16:23:29,673] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2019-08-14 16:23:29,690] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2019-08-14 16:23:29,703] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2019-08-14 16:23:29,711] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.IPySparkInterpreter
 INFO [2019-08-14 16:23:29,713] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkRInterpreter
 WARN [2019-08-14 16:23:29,804] ({pool-1-thread-3} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2019-08-14 16:23:29,834] ({pool-1-thread-3} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2019-08-14 16:23:29,834] ({pool-1-thread-3} ZeppelinConfiguration.java[create]:131) - Server Port: 8080
 INFO [2019-08-14 16:23:29,834] ({pool-1-thread-3} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2019-08-14 16:23:29,837] ({pool-1-thread-3} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.1
 INFO [2019-08-14 16:23:29,839] ({pool-1-thread-3} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 INFO [2019-08-14 16:23:29,851] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20190814-162321_1380380680 started by scheduler interpreter_1929209844
 INFO [2019-08-14 16:23:29,935] ({pool-2-thread-2} NewSparkInterpreter.java[open]:83) - Using Scala Version: 2.11
 INFO [2019-08-14 16:23:36,002] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Running Spark version 2.2.1
 WARN [2019-08-14 16:23:36,345] ({pool-2-thread-2} NativeCodeLoader.java[<clinit>]:62) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO [2019-08-14 16:23:36,531] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Submitted application: Zeppelin
 INFO [2019-08-14 16:23:36,563] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing view acls to: root
 INFO [2019-08-14 16:23:36,564] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing modify acls to: root
 INFO [2019-08-14 16:23:36,568] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing view acls groups to: 
 INFO [2019-08-14 16:23:36,569] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing modify acls groups to: 
 INFO [2019-08-14 16:23:36,570] ({pool-2-thread-2} Logging.scala[logInfo]:54) - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
 INFO [2019-08-14 16:23:36,975] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'sparkDriver' on port 46345.
 INFO [2019-08-14 16:23:37,009] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering MapOutputTracker
 INFO [2019-08-14 16:23:37,040] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering BlockManagerMaster
 INFO [2019-08-14 16:23:37,045] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO [2019-08-14 16:23:37,045] ({pool-2-thread-2} Logging.scala[logInfo]:54) - BlockManagerMasterEndpoint up
 INFO [2019-08-14 16:23:37,060] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Created local directory at /tmp/blockmgr-dcf1c405-c548-4eb3-8f64-d36421ace6e9
 INFO [2019-08-14 16:23:37,090] ({pool-2-thread-2} Logging.scala[logInfo]:54) - MemoryStore started with capacity 408.9 MB
 INFO [2019-08-14 16:23:37,152] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering OutputCommitCoordinator
 INFO [2019-08-14 16:23:37,314] ({pool-2-thread-2} Log.java[initialized]:192) - Logging initialized @9440ms
 INFO [2019-08-14 16:23:37,402] ({pool-2-thread-2} Server.java[doStart]:345) - jetty-9.3.z-SNAPSHOT
 INFO [2019-08-14 16:23:37,421] ({pool-2-thread-2} Server.java[doStart]:403) - Started @9547ms
 INFO [2019-08-14 16:23:37,447] ({pool-2-thread-2} AbstractConnector.java[doStart]:270) - Started ServerConnector@505c600a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
 INFO [2019-08-14 16:23:37,447] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'SparkUI' on port 4040.
 INFO [2019-08-14 16:23:37,486] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@72bc9964{/jobs,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,487] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@7c9b504d{/jobs/json,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,487] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6c91bcea{/jobs/job,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,488] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6cad8cd1{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,489] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@497a0dbe{/stages,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,491] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@528c67f2{/stages/json,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,492] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@163fed5f{/stages/stage,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,494] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@26bbaa1e{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,494] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5431992{/stages/pool,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,495] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@eb9ff2c{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,495] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2a0d27b8{/storage,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,496] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@549cf80c{/storage/json,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,496] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5904b479{/storage/rdd,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,496] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@16221fbd{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,497] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4b2c844a{/environment,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,498] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@68f4bb0{/environment/json,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,498] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2499eb68{/executors,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,498] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6b4dce6f{/executors/json,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,499] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4a123a5b{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,499] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@46ecea47{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,505] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@660afe01{/static,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,507] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@7fb64e8d{/,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,509] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@495a2b3{/api,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,510] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@fb39996{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,511] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6bbea1a5{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:23:37,522] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Bound SparkUI to 0.0.0.0, and started at http://172.17.0.3:4040
 INFO [2019-08-14 16:23:37,559] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Added JAR /zeppelin/interpreter/spark/spark-interpreter-0.8.1.jar at spark://172.17.0.3:46345/jars/spark-interpreter-0.8.1.jar with timestamp 1565799817558
 INFO [2019-08-14 16:23:37,663] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Starting executor ID driver on host localhost
 INFO [2019-08-14 16:23:37,672] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Using REPL class URI: spark://172.17.0.3:46345/classes
 INFO [2019-08-14 16:23:37,731] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46715.
 INFO [2019-08-14 16:23:37,732] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Server created on 172.17.0.3:46715
 INFO [2019-08-14 16:23:37,733] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO [2019-08-14 16:23:37,734] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering BlockManager BlockManagerId(driver, 172.17.0.3, 46715, None)
 INFO [2019-08-14 16:23:37,744] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Registering block manager 172.17.0.3:46715 with 408.9 MB RAM, BlockManagerId(driver, 172.17.0.3, 46715, None)
 INFO [2019-08-14 16:23:37,752] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registered BlockManager BlockManagerId(driver, 172.17.0.3, 46715, None)
 INFO [2019-08-14 16:23:37,752] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Initialized BlockManager: BlockManagerId(driver, 172.17.0.3, 46715, None)
 INFO [2019-08-14 16:23:37,952] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@599305f5{/metrics/json,null,AVAILABLE,@Spark}
 INFO [2019-08-14 16:25:10,991] ({pool-2-thread-2} SparkShims.java[loadShims]:62) - Initializing shims for Spark 2.x
 INFO [2019-08-14 16:25:11,598] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20190814-162321_1380380680 finished by scheduler interpreter_1929209844
 INFO [2019-08-14 16:47:38,770] ({pool-1-thread-1} NewSparkInterpreter.java[close]:134) - Close SparkInterpreter
 INFO [2019-08-14 16:47:38,839] ({pool-1-thread-1} AbstractConnector.java[doStop]:310) - Stopped Spark@505c600a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
 INFO [2019-08-14 16:47:38,843] ({pool-1-thread-1} Logging.scala[logInfo]:54) - Stopped Spark web UI at http://172.17.0.3:4040
 INFO [2019-08-14 16:47:38,873] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - MapOutputTrackerMasterEndpoint stopped!
 INFO [2019-08-14 16:47:38,911] ({pool-1-thread-1} Logging.scala[logInfo]:54) - MemoryStore cleared
 INFO [2019-08-14 16:47:38,912] ({pool-1-thread-1} Logging.scala[logInfo]:54) - BlockManager stopped
 INFO [2019-08-14 16:47:38,914] ({pool-1-thread-1} Logging.scala[logInfo]:54) - BlockManagerMaster stopped
 INFO [2019-08-14 16:47:38,924] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - OutputCommitCoordinator stopped!
 INFO [2019-08-14 16:47:38,932] ({pool-1-thread-1} Logging.scala[logInfo]:54) - Successfully stopped SparkContext
 INFO [2019-08-14 16:47:38,937] ({pool-1-thread-1} Logging.scala[logInfo]:54) - SparkContext already stopped.
 INFO [2019-08-14 16:47:38,985] ({pool-1-thread-1} RemoteInterpreterServer.java[shutdown]:209) - Shutting down...
 INFO [2019-08-14 16:47:41,136] ({Thread-5} Logging.scala[logInfo]:54) - Shutdown hook called
 INFO [2019-08-14 16:47:41,139] ({Thread-5} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-6c6d5b6f-c96f-45da-80ee-c44b1039e389
